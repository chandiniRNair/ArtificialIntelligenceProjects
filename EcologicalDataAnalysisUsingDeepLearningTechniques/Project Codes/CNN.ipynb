{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['LF' 0 3.5 ..., 0.0 0.0 0.0]\n",
      " ['FR' 0 3.5 ..., 0.0 0.0 0.0]\n",
      " ['LF' 0 3.5 ..., 0.0 0.0 0.0]\n",
      " ..., \n",
      " ['FR' 1 3.5 ..., 0.0 0.0 0.0]\n",
      " ['LF' 0 3.5 ..., 0.0 0.0 0.0]\n",
      " ['FR' 1 3.5 ..., 0.0 0.0 0.0]]\n",
      "10500 train samples\n",
      "3150 test samples\n",
      "[[ 0.  0.  1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " ..., \n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  1.  0.]]\n",
      "[[ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " ..., \n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 171, 50)           525000    \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 169, 128)          19328     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 561,227\n",
      "Trainable params: 561,227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6300 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "6300/6300 [==============================] - 57s - loss: 1.0989 - acc: 0.3294 - val_loss: 1.1001 - val_acc: 0.3305\n",
      "Epoch 2/10\n",
      "6300/6300 [==============================] - 56s - loss: 1.0990 - acc: 0.3367 - val_loss: 1.0992 - val_acc: 0.3243\n",
      "Epoch 3/10\n",
      "6300/6300 [==============================] - 56s - loss: 1.0987 - acc: 0.3302 - val_loss: 1.0991 - val_acc: 0.3243\n",
      "Epoch 4/10\n",
      "6300/6300 [==============================] - 57s - loss: 1.0987 - acc: 0.3367 - val_loss: 1.0989 - val_acc: 0.3243\n",
      "Epoch 5/10\n",
      "6300/6300 [==============================] - 58s - loss: 1.0987 - acc: 0.3327 - val_loss: 1.0990 - val_acc: 0.3243\n",
      "Epoch 6/10\n",
      "6300/6300 [==============================] - 56s - loss: 1.0986 - acc: 0.3381 - val_loss: 1.0991 - val_acc: 0.3243\n",
      "Epoch 7/10\n",
      "6300/6300 [==============================] - 56s - loss: 1.0986 - acc: 0.3360 - val_loss: 1.0991 - val_acc: 0.3243\n",
      "Epoch 8/10\n",
      "6300/6300 [==============================] - 56s - loss: 1.0986 - acc: 0.3371 - val_loss: 1.0991 - val_acc: 0.3243\n",
      "Epoch 9/10\n",
      "6300/6300 [==============================] - 56s - loss: 1.0985 - acc: 0.3371 - val_loss: 1.0992 - val_acc: 0.3243\n",
      "Epoch 10/10\n",
      "6300/6300 [==============================] - 56s - loss: 1.0986 - acc: 0.3405 - val_loss: 1.0992 - val_acc: 0.3243\n",
      "3136/3150 [============================>.] - ETA: 0s\n",
      "Test score: 1.09875658527\n",
      "Test accuracy: 0.333333333343\n"
     ]
    }
   ],
   "source": [
    "#program to implement convolutional neural network for classification\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Activation,Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(1671)\n",
    "NB_EPOCH = 10\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 3\n",
    "OPTIMIZER = Adam()\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT=0.4\n",
    "RESHAPED = 171\n",
    "dataframe_train = pandas.read_csv(\"TrainingEdgesToAction.csv\", header=None)\n",
    "dataset_train_v = dataframe_train.values\n",
    "dataset_train_f = dataset_train_v[1:,0:172]\n",
    "#Shuffling of the data set\n",
    "dataset_train_n = shuffle(dataset_train_f)\n",
    "print(dataset_train_n)\n",
    "\n",
    "X_train = dataset_train_n[0:,1:172].astype(float)\n",
    "Y_train = dataset_train_n[0:,0]\n",
    "\n",
    "\n",
    "\n",
    "dataframe_test = pandas.read_csv(\"TestingEdgesToAction.csv\", header=None)\n",
    "dataset_test = dataframe_test.values\n",
    "dataset_test_ft = dataset_test[1:,0:172]\n",
    "#Shuffling of the data set\n",
    "dataset_test_nt = shuffle(dataset_test_ft)\n",
    "X_test = dataset_test_nt[0:,1:172].astype(float)\n",
    "Y_test = dataset_test_nt[0:,0]\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(10500,RESHAPED)\n",
    "X_test = X_test.reshape(3150,RESHAPED)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(X_train.shape[0],'train samples')\n",
    "print(X_test.shape[0],'test samples')\n",
    "\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_train)\n",
    "encoded_Y_train = encoder.transform(Y_train)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_train = np_utils.to_categorical(encoded_Y_train)\n",
    "print(dummy_y_train)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_test)\n",
    "encoded_Y_test = encoder.transform(Y_test)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_test = np_utils.to_categorical(encoded_Y_test)\n",
    "print(dummy_y_test)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10500,50,input_length=171))\n",
    "model.add(Conv1D(128,3,padding='valid',activation='relu',strides=1))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',optimizer=OPTIMIZER,metrics=['accuracy'])\n",
    "history = model.fit(X_train,dummy_y_train,batch_size=BATCH_SIZE,epochs=NB_EPOCH,verbose=VERBOSE,validation_split=VALIDATION_SPLIT)\n",
    "score = model.evaluate(X_test,dummy_y_test,verbose=VERBOSE)\n",
    "\n",
    "print(\"\\nTest score:\",score[0])\n",
    "print(\"Test accuracy:\",score[1])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
